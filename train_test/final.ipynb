{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7780d36",
   "metadata": {},
   "source": [
    "# 2_wheeler and 4_wheeler classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65d4e5",
   "metadata": {},
   "source": [
    "## 1. ChatGPT fast working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508b70f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Set the path to the dataset directories\n",
    "dataset_dir = 'datasets'\n",
    "two_wheeler_dir = os.path.join(dataset_dir, 'bike')\n",
    "four_wheeler_dir = os.path.join(dataset_dir, 'car')\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def load_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images of two-wheelers\n",
    "    for filename in os.listdir(two_wheeler_dir):\n",
    "        img = cv2.imread(os.path.join(two_wheeler_dir, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append('bike')\n",
    "\n",
    "    # Load images of four-wheelers\n",
    "    for filename in os.listdir(four_wheeler_dir):\n",
    "        img = cv2.imread(os.path.join(four_wheeler_dir, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append('car')\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "def split_dataset(images, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Preprocess and normalize the images\n",
    "def preprocess_images(X_train, X_test):\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    return X_train, X_test\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "def encode_labels(y_train, y_test):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return y_train, y_test\n",
    "\n",
    "# Build the CNN model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "images, labels = load_dataset()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = split_dataset(images, labels)\n",
    "\n",
    "# Preprocess and normalize the images\n",
    "X_train, X_test = preprocess_images(X_train, X_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train, y_test = encode_labels(y_train, y_test)\n",
    "\n",
    "# Build the CNN model\n",
    "model = build_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('\\nTest Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abd8b3",
   "metadata": {},
   "source": [
    "## some what working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import save_model\n",
    "\n",
    "# Set the path to the dataset directories\n",
    "dataset_dir = 'datasets'\n",
    "two_wheeler_dir = os.path.join(dataset_dir, 'bike')\n",
    "four_wheeler_dir = os.path.join(dataset_dir, 'car')\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def load_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images of two-wheelers\n",
    "    for filename in os.listdir(two_wheeler_dir):\n",
    "        img = cv2.imread(os.path.join(two_wheeler_dir, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append('bike')\n",
    "\n",
    "    # Load images of four-wheelers\n",
    "    for filename in os.listdir(four_wheeler_dir):\n",
    "        img = cv2.imread(os.path.join(four_wheeler_dir, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append('car')\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "def split_dataset(images, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Preprocess and normalize the images\n",
    "def preprocess_images(X_train, X_test):\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    return X_train, X_test\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "def encode_labels(y_train, y_test):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return y_train, y_test, label_encoder\n",
    "\n",
    "# Build the CNN model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "images, labels = load_dataset()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = split_dataset(images, labels)\n",
    "\n",
    "# Preprocess and normalize the images\n",
    "X_train, X_test = preprocess_images(X_train, X_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train, y_test, label_encoder = encode_labels(y_train, y_test)\n",
    "\n",
    "# Build the CNN model\n",
    "model = build_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "save_model(model, 'vehicle_classification_model.h5')\n",
    "\n",
    "# Save the label encoder classes\n",
    "np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('\\nTest Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49712d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from flask import Flask, request, render_template\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Set the path to the dataset directories\n",
    "dataset_dir = 'datasets'\n",
    "two_wheeler_dir = os.path.join(dataset_dir, 'bike')\n",
    "four_wheeler_dir = os.path.join(dataset_dir, 'car')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('vehicle_classification_model.h5')\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('label_encoder_classes.npy')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Preprocess the uploaded image\n",
    "def preprocess_image(image):\n",
    "    img = cv2.imdecode(np.fromstring(image.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Predict the class of the uploaded image\n",
    "def predict_class(image):\n",
    "    img = preprocess_image(image)\n",
    "    prediction = model.predict(img)\n",
    "    class_index = np.argmax(prediction)\n",
    "    vehicle_class = label_encoder.classes_[class_index]\n",
    "    return vehicle_class\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def classify_vehicle():\n",
    "    if request.method == 'POST':\n",
    "        if 'image' not in request.files:\n",
    "            return render_template('index.html', message='No image file selected.')\n",
    "        \n",
    "        image = request.files['image']\n",
    "        \n",
    "        if image.filename == '':\n",
    "            return render_template('index.html', message='No image file selected.')\n",
    "        \n",
    "        vehicle_class = predict_class(image)\n",
    "        \n",
    "        return render_template('index.html', message='Predicted class: {}'.format(vehicle_class))\n",
    "    \n",
    "    return render_template('index.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
